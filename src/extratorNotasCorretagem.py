import pdfplumber
import pandas as pd
import re
import os
import zipfile
import logging
import signal
import sys
import argparse
from io import BytesIO
from datetime import datetime
from typing import Dict, List, Optional
from tqdm import tqdm
from config import get_config

# Carregar configura√ß√µes
config = get_config()

# Configura√ß√£o de Logging
logging_level = config.get_logging_level()
logs_folder = config.resolve_path(config.get_logs_folder())

# Criar pasta de logs se n√£o existir
if not os.path.exists(logs_folder):
    os.makedirs(logs_folder)

# Gera nome do arquivo de log com timestamp
log_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
log_file = os.path.join(logs_folder, f"extracao_{log_timestamp}.log")

# Configurar logging com ambos console e arquivo
logging.basicConfig(
    level=getattr(logging, logging_level),
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%d/%m/%Y %H:%M:%S',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Flag para controle de interrup√ß√£o pelo usu√°rio (Ctrl+C)
stop_processing = False

def _handle_sigint(signum, frame):
    global stop_processing
    if not stop_processing:
        stop_processing = True
        logger.warning("‚è∏Ô∏è Interrup√ß√£o solicitada pelo usu√°rio (Ctrl+C). Finalizando ap√≥s o arquivo atual...")
    else:
        logger.error("‚úñ For√ßando sa√≠da imediata por novo Ctrl+C")
        sys.exit(1)

# Registra o handler para SIGINT
signal.signal(signal.SIGINT, _handle_sigint)

def _count_total_pdfs(caminho):
    """Conta o total estimado de PDFs que ser√£o processados a partir do caminho.
    Suporta arquivo ZIP √∫nico, pasta com PDFs e/ou ZIPs, e caminho para pasta com PDFs diretos.
    """
    try:
        if caminho.endswith('.zip') or (os.path.isfile(caminho) and zipfile.is_zipfile(caminho)):
            with zipfile.ZipFile(caminho, 'r') as z:
                return len([f for f in z.namelist() if f.endswith('.pdf')])

        if os.path.isdir(caminho):
            total = 0
            # PDFs diretos
            total += len([f for f in os.listdir(caminho) if f.endswith('.pdf')])
            # PDFs dentro de ZIPs na pasta
            zips = [f for f in os.listdir(caminho) if f.endswith('.zip')]
            for zf in zips:
                try:
                    with zipfile.ZipFile(os.path.join(caminho, zf), 'r') as z:
                        total += len([f for f in z.namelist() if f.endswith('.pdf')])
                except Exception:
                    continue
            return total

        return 0
    except Exception:
        return 0

# 1. Dicion√°rio De-Para para mapear nomes de ativos para Tickers
# Baseado nos exemplos dos fontes como "FIAGRO SUNO" [6] e "SUNO FIC FI" [7]
DE_PARA_TICKERS = {
    "PORTOSEGURO": "PSSA3",
    "PETROBRAS": "PETR3",
    "COPEL ON ED N1": "CPLE3",
    "NEOENERGIA ON NM": "NEOE3",
    "VALE ON": "VALE3",
    #"FIAGRO SUNO": "SNAG11",
    #"SUNO FIC FI": "SNCI11",
    #"FII ATRIO": "ARRI11",
    #"FII KINEA RI": "KNCR11",
    #"FII HSI CRI": "HSAF11"
}

def criar_bytesio_com_nome(conteudo, nome_arquivo):
    """Cria um BytesIO com atributo 'name' para compatibilidade."""
    bio = BytesIO(conteudo)
    bio.name = nome_arquivo
    return bio

def limpar_ticker(texto, dicionario):
    """Extrai o ticker ou usa o de-para para nomes conhecidos."""
    texto = texto.replace('\n', ' ').strip()
    # Tenta encontrar um padr√£o de Ticker (4 letras + 2 n√∫meros)
    match = re.search(r'[A-Z]{4}\d{2}', texto)
    if match:
        return match.group(0)
    
    # Se n√£o achar o Ticker puro, busca no dicion√°rio De-Para
    for nome, ticker in dicionario.items():
        if nome in texto.upper():
            return ticker
    return texto # Retorna o original se n√£o mapear


def _normalize_number(text):
    """Converte n√∫meros no formato brasileiro para ponto decimal (ex: '1.234,56' -> '1234.56')."""
    if not text:
        return ''
    s = str(text).strip()
    # Remove espa√ßos e s√≠mbolos extras
    s = s.replace('\xa0', '').replace(' ', '')
    # Se j√° tem apenas d√≠gitos e ponto, tenta retornar
    # Substitui milhares (.) e decimal (,) -> '.'
    # Primeiro, remove pontos que representam milhares
    # Mas cuidado: se houver apenas one dot and no comma, keep it
    if ',' in s:
        s = s.replace('.', '')
        s = s.replace(',', '.')
    else:
        # Remove any non-digit or dot
        s = re.sub(r'[^0-9\.]', '', s)
    return s


def _is_likely_header(cells):
    """Verifica se a linha parece ser um cabe√ßalho (nomes de colunas)."""
    if not cells:
        return False
    
    # Palavras t√≠picas de cabe√ßalhos
    header_keywords = ['data', 'ativo', 'especif', 'qtd', 'pre√ßo', 'valor', 'opera√ß√£o', 'nota', 'corretora']
    header_text = ' '.join([str(c).lower() for c in cells if c])
    
    # Se muitas c√©lulas t√™m pontos/dois-pontos, pode ser cabe√ßalho
    if header_text.count(':') > 3:
        return True
    
    # Se cont√©m m√∫ltiplas palavras de cabe√ßalho
    count = sum(1 for kw in header_keywords if kw in header_text)
    return count >= 2

def _is_valid_data_row(cells, is_negotiation_table=False):
    """Verifica se a linha parece ser um registro de negocia√ß√£o e n√£o cabe√ßalho/resumo/footer.
    
    Args:
        cells: List of cell values from the row
        is_negotiation_table: True if this is an 11-column negotiation table (less strict validation)
    """
    if not cells or len(cells) < 2:
        return False
    
    # Rejeita se parece ser cabe√ßalho
    if _is_likely_header(cells):
        return False
    
    # Palavras-chave que indicam linhas que N√ÉO s√£o negocia√ß√µes (headers, footers, summaries)
    skip_keywords = [
        'resumo', 'total', 'deb√™ntures', 'vendas', 'compras', 'op√ß√µes', 'termo',
        'taxa', 'emolumentos', 'transf', 'ativos', 'custodiante', 'clearing',
        'especifica√ß√µes', 'bovespa', 'cblc', 'cliente', 'c√≥digo', 'assessor',
        'participante', 'folha', 'data preg√£o', 'negocia√ß√£o', 'c.p.f', 'cnpj',
        'valor das oper', 'valor l√≠quido', 'qualificado', 'nota de negocia√ß√£o',
        'impostos', 'i.r.r.f', 'execu√ß√£o', 'cust√≥dia', 'bolsa', 'operacional',
        'custos', 'agente', 'qualificado', 'especifica√ß√µes diversas',
        'coluna q', 'liquida√ß√£o', 'agente do qualificado', '(*)', 'observa√ß√µes',
        'l√≠quido para',  # Settlement rows, not transactions
        'conta', 'saldo', 'c.m.c', 'participante destino'  # Account/routing info
    ]
    
    # Para tabelas de negocia√ß√£o (11 colunas), valida√ß√£o menos rigorosa
    if is_negotiation_table:
        # Apenas rejeita se tem palavras-chave muito √≥bvias (menos a de "bovespa")
        strict_skip = [
            'resumo', 'total', 'deb√™ntures', 'taxa', 'emolumentos', 'custos',
            'l√≠quido para', 'client', 'c√≥digo', 'c.p.f', 'cnpj', 'observa√ß√µes',
            '(*)', 'saldo', 'conta'
        ]
        row_text = ' '.join(cells).upper()
        for keyword in strict_skip:
            if keyword.upper() in row_text:
                return False
    else:
        # Para outras tabelas, valida√ß√£o rigorosa
        row_text = ' '.join(cells).upper()
        for keyword in skip_keywords:
            if keyword.upper() in row_text:
                return False
    
    # Uma linha v√°lida deve ter pelo menos um n√∫mero (quantidade ou pre√ßo)
    has_number = False
    for cell in cells:
        # Aceita tanto n√∫meros decimais quanto inteiros
        if re.search(r'\d', str(cell)):
            has_number = True
            break
    
    return has_number


def _extract_ticker_from_cells(cells, ticker_mapping=None):
    """
    Extrai ticker da linha, buscando padr√£o B3 ou nome de ativo conhecido.
    
    Estrat√©gia:
    1. Procura por padr√£o ticker B3 (4 letras + 2 d√≠gitos)
    2. Busca em DE_PARA_TICKERS (hardcoded)
    3. Busca em ticker_mapping (carregado de resouces/tickerMapping.properties)
    """
    for cell in cells:
        cell_str = str(cell).strip()
        
        # Tenta padr√£o ticker B3 (4 letras + 2 d√≠gitos)
        match = re.search(r'[A-Z]{4}\d{2}', cell_str)
        if match:
            return match.group(0)
        
        # Tenta encontrar nome conhecido de ativo (DE_PARA hardcoded)
        for nome, ticker in DE_PARA_TICKERS.items():
            if nome.upper() in cell_str.upper():
                return ticker
        
        # Tenta ticker_mapping (carregado de arquivo de configura√ß√£o)
        if ticker_mapping:
            for nome, ticker in ticker_mapping.items():
                if nome.upper() in cell_str.upper():
                    return ticker
    
    # Se n√£o encontrou padr√£o, retorna None (linha provavelmente n√£o √© v√°lida)
    return None

def _extract_year_from_filename(filename: str) -> Optional[int]:
    """Extrai o ano do nome do arquivo PDF.
    
    Procura por padr√µes como:
    - Clear 2026 01 Janeiro
    - Clear 2025 12 Dezembro
    - Arquivo_2024_01_Janeiro
    
    Args:
        filename: Nome do arquivo PDF
        
    Returns:
        Ano extra√≠do como inteiro, ou None se n√£o encontrar
    """
    # Padr√£o: 4 d√≠gitos que representam um ano (entre 1900 e 2100)
    match = re.search(r'\b(19|20)\d{2}\b', filename)
    if match:
        return int(match.group(0))
    return None

def _should_process_file(filename: str, target_year: Optional[int]) -> bool:
    """Verifica se o arquivo deve ser processado baseado no filtro de ano.
    
    Args:
        filename: Nome do arquivo
        target_year: Ano desejado (None = processar todos)
        
    Returns:
        True se deve processar, False caso contr√°rio
    """
    if target_year is None:
        return True
    
    file_year = _extract_year_from_filename(filename)
    if file_year is None:
        logger.warning(f"‚ö†Ô∏è  N√£o foi poss√≠vel extrair ano de: {filename}")
        return False
    
    return file_year == target_year


def processar_pdf(pdf_file, senha=None):
    dados_extraidos = []
    
    # Carrega mapeamento de tickers do arquivo de configura√ß√£o
    ticker_mapping = config.get_ticker_mapping()
    
    # Tratamento inteligente do nome do arquivo para diferentes tipos de entrada
    if isinstance(pdf_file, str):
        arquivo_nome = os.path.basename(pdf_file)
    else:
        # Para file objects e BytesIO, tenta obter 'name', sen√£o usa gen√©rico
        arquivo_nome = getattr(pdf_file, 'name', 'pdf_temporario.pdf')
    
    try:
        logger.info(f"üìÑ Processando arquivo: {arquivo_nome}")
        
        # Tenta abrir com senha se fornecida
        try:
            if senha:
                pdf = pdfplumber.open(pdf_file, password=senha)
            else:
                pdf = pdfplumber.open(pdf_file)
        except pdfplumber.utils.exceptions.PdfminerException:
            # Se falhar sem senha, tenta com a senha padr√£o da config
            try:
                senha_config = config.get_pdf_password()
                if senha_config:
                    pdf = pdfplumber.open(pdf_file, password=senha_config)
                else:
                    raise
            except:
                logger.warning(f"‚ö†Ô∏è  {arquivo_nome}: PDF protegido. Configure 'pdf.password' em application.properties")
                return dados_extraidos
        
        with pdf:
            total_paginas = len(pdf.pages)
            logger.debug(f"   Total de p√°ginas: {total_paginas}")
            
            for num_pagina, page in enumerate(pdf.pages, 1):
                try:
                    # Extra√ß√£o da Data (procura por "Data preg√£o") [3, 8, 9]
                    texto_topo = page.extract_text()
                    data_pregao = None
                    match_data = re.search(r'(\d{2}/\d{2}/\d{4})', texto_topo)
                    if match_data:
                        data_pregao = match_data.group(1)

                    # Extra√ß√£o da Tabela de Neg√≥cios [1, 2, 10]
                    tables = page.extract_tables()
                    registros_pagina = 0
                    
                    for table in tables:
                        if not table:
                            continue

                        # Detecta tabelas de negocia√ß√µes ‚Äî geralmente 11 colunas em muitas corretoras
                        num_cols = len(table[0]) if table and table[0] else 0
                        table_text = ' '.join(' '.join([str(c) for c in row if c]) for row in table)
                        is_negociacao = (num_cols == 11) or any(k in table_text for k in ['Data preg√£o', 'Nr. nota', 'Negocia√ß√£o', 'Especifica√ß√£o'])

                        if not is_negociacao:
                            # Heur√≠stica fallback: tente encontrar linhas que contenham quantidade+pre√ßo
                            # MAS USANDO A MESMA VALIDA√á√ÉO que acima
                            for row in table[1:]:
                                if not row or all(not (str(c).strip()) for c in row):
                                    continue

                                cells = [(c or '').strip() for c in row]
                                
                                # APLICAR VALIDA√á√ÉO: recusa headers/footers/summaries
                                if not _is_valid_data_row(cells, is_negotiation_table=False):
                                    continue
                                
                                try:
                                    # Verifica se √© uma linha v√°lida de negocia√ß√£o
                                    ticker = _extract_ticker_from_cells(cells, ticker_mapping)
                                    if not ticker:
                                        continue  # N√£o conseguiu extrair ticker v√°lido

                                    # Procura por padr√µes de n√∫mero (quantidade/price)
                                    possible_qty = None
                                    possible_price = None
                                    for c in cells:
                                        if re.search(r'\d+[\.,]\d+', c):
                                            # assume price-like
                                            if not possible_price:
                                                possible_price = _normalize_number(c)
                                        elif re.search(r'^\d+$', c.replace('.', '').replace(',', '')):
                                            if not possible_qty:
                                                possible_qty = _normalize_number(c)

                                    if not possible_qty and not possible_price:
                                        continue

                                    operacao = ''
                                    for c in cells:
                                        if ' C ' in f' {c} '.upper() or c.strip().upper() == 'C' or c.strip().upper() == 'V':
                                            operacao = 'C' if 'C' in c.upper() else 'V' if 'V' in c.upper() else ''
                                            if operacao:
                                                break

                                    dados_extraidos.append({
                                        "Data": data_pregao,
                                        "Ticker": ticker,
                                        "Opera√ß√£o": operacao,
                                        "Quantidade": possible_qty or '',
                                        "Pre√ßo": possible_price or ''
                                    })
                                    registros_pagina += 1
                                except Exception:
                                    continue
                            # fim heur√≠stica fallback
                        else:
                            # Para tabelas de negocia√ß√£o, processa TODAS as linhas (n√£o pula a primeira)
                            # A detec√ß√£o de cabe√ßalho √© feita dentro de _is_valid_data_row()
                            start_row = 0 if is_negociacao else 1
                            for row in table[start_row:]:
                                # Filtra linhas vazias
                                if not row or all(not (str(c).strip()) for c in row):
                                    continue

                                cells = [(c or '').strip() for c in row]
                                
                                # Verifica se √© uma linha v√°lida de negocia√ß√£o
                                if not _is_valid_data_row(cells, is_negotiation_table=True):
                                    continue

                                try:
                                    # Mapeamento comum observado em amostras:
                                    # col[2] = opera√ß√£o (C/V), col[5] = especifica√ß√£o (nome do ativo), col[7] = quantidade, col[8] = pre√ßo
                                    
                                    # Extrai ticker de forma robusta
                                    ticker = _extract_ticker_from_cells(cells, ticker_mapping)
                                    if not ticker:
                                        continue  # N√£o conseguiu extrair ticker v√°lido
                                    
                                    operacao = ''
                                    if len(cells) > 2 and cells[2]:
                                        operacao = 'C' if 'C' in cells[2].upper() else ('V' if 'V' in cells[2].upper() else '')

                                    quantidade_raw = cells[7] if len(cells) > 7 else ''
                                    preco_raw = cells[8] if len(cells) > 8 else ''

                                    quantidade = _normalize_number(quantidade_raw)
                                    preco = _normalize_number(preco_raw)

                                    # Se n√£o houver quantidade nem pre√ßo, provavelmente n√£o √© linha de neg√≥cio
                                    if not quantidade and not preco:
                                        continue

                                    dados_extraidos.append({
                                        "Data": data_pregao,
                                        "Ticker": ticker,
                                        "Opera√ß√£o": operacao,
                                        "Quantidade": quantidade,
                                        "Pre√ßo": preco
                                    })
                                    registros_pagina += 1
                                except Exception as e:
                                    logger.debug(f"   ‚ö†Ô∏è  Erro ao extrair linha: {str(e)}")
                                    continue
                    
                    if registros_pagina > 0:
                        logger.debug(f"   ‚úì P√°gina {num_pagina}/{total_paginas}: {registros_pagina} registro(s) extra√≠do(s)")
                        
                except Exception as e:
                    logger.error(f"   ‚úó Erro ao processar p√°gina {num_pagina}: {str(e)}")
                    continue
        
        total_registros = len(dados_extraidos)
        if total_registros > 0:
            logger.info(f"‚úì {arquivo_nome}: {total_registros} registro(s) extra√≠do(s) com sucesso")
        else:
            logger.warning(f"‚ö†Ô∏è  {arquivo_nome}: Nenhum registro extra√≠do")
            
    except FileNotFoundError:
        logger.error(f"‚úó Arquivo n√£o encontrado: {arquivo_nome}")
    except Exception as e:
        logger.error(f"‚úó Erro ao processar {arquivo_nome}: {str(e)}")
    
    return dados_extraidos

def analisar_pasta_ou_zip(caminho, year_filter: Optional[int] = None):
    todos_dados = []
    arquivos_processados = 0
    arquivos_erro = 0
    arquivos_ignorados = 0

    try:
        logger.info("=" * 60)
        logger.info("üöÄ INICIANDO PROCESSAMENTO")
        if year_filter is not None:
            logger.info(f"üîç Filtro de ano ativo: {year_filter}")
        logger.info("=" * 60)

        # Resolve caminho relativo se necess√°rio
        if not os.path.isabs(caminho):
            caminho_resolvido = os.path.join(os.path.dirname(__file__), caminho)
            if os.path.exists(caminho_resolvido):
                caminho = caminho_resolvido

        # Valida√ß√£o do caminho fornecido
        if not os.path.exists(caminho):
            logger.error(f"‚úó Caminho n√£o encontrado: {caminho}")
            return pd.DataFrame()

        total_arquivos = _count_total_pdfs(caminho)
        logger.info(f"üì• Total estimado de PDFs para processar: {total_arquivos}")

        if total_arquivos == 0:
            logger.warning("‚ö†Ô∏è  Nenhum arquivo PDF encontrado para processar")
            return pd.DataFrame()

        # Cria a lista de tarefas (uniformiza arquivos diretos e dentro de ZIPs)
        tarefas = []

        if caminho.endswith('.zip') or (os.path.isfile(caminho) and zipfile.is_zipfile(caminho)):
            tarefas_tipo = 'single_zip'
            with zipfile.ZipFile(caminho, 'r') as z:
                for f in z.namelist():
                    if f.endswith('.pdf'):
                        # Aplica filtro de ano se especificado
                        if _should_process_file(f, year_filter):
                            tarefas.append({'type': 'zip_entry', 'zip': caminho, 'name': f})
                        else:
                            arquivos_ignorados += 1

        elif os.path.isdir(caminho):
            # PDFs diretos
            for f in os.listdir(caminho):
                if f.endswith('.pdf'):
                    # Aplica filtro de ano se especificado
                    if _should_process_file(f, year_filter):
                        tarefas.append({'type': 'file', 'path': os.path.join(caminho, f)})
                    else:
                        arquivos_ignorados += 1

            # PDFs dentro de ZIPs na pasta
            for zf in [f for f in os.listdir(caminho) if f.endswith('.zip')]:
                caminho_zip = os.path.join(caminho, zf)
                try:
                    with zipfile.ZipFile(caminho_zip, 'r') as z:
                        for entry in z.namelist():
                            if entry.endswith('.pdf'):
                                # Aplica filtro de ano se especificado
                                if _should_process_file(entry, year_filter):
                                    tarefas.append({'type': 'zip_entry', 'zip': caminho_zip, 'name': entry})
                                else:
                                    arquivos_ignorados += 1
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  N√£o foi poss√≠vel listar ZIP {zf}: {str(e)}")

        else:
            logger.error(f"‚úó Caminho n√£o √© arquivo ZIP ou pasta: {caminho}")
            return pd.DataFrame()

        # Barra de progresso global para todos os PDFs
        with tqdm(total=len(tarefas), desc="üì• Processando PDFs", unit="arquivo") as pbar:
            try:
                for tarefa in tarefas:
                    if stop_processing:
                        logger.warning("‚è∏Ô∏è Interrup√ß√£o detectada ‚Äî finalizando processamento ap√≥s o arquivo atual.")
                        break

                    if tarefa['type'] == 'file':
                        try:
                            dados = processar_pdf(tarefa['path'])
                            todos_dados.extend(dados)
                            arquivos_processados += 1
                        except Exception as e:
                            logger.error(f"‚úó Erro ao processar {tarefa['path']}: {str(e)}")
                            arquivos_erro += 1
                        finally:
                            pbar.update(1)

                    elif tarefa['type'] == 'zip_entry':
                        try:
                            with zipfile.ZipFile(tarefa['zip'], 'r') as z:
                                with z.open(tarefa['name']) as f:
                                    bio = criar_bytesio_com_nome(f.read(), os.path.basename(tarefa['name']))
                                    dados = processar_pdf(bio)
                                    todos_dados.extend(dados)
                                    arquivos_processados += 1
                        except Exception as e:
                            logger.error(f"‚úó Erro ao processar {tarefa['name']} do ZIP {os.path.basename(tarefa['zip'])}: {str(e)}")
                            arquivos_erro += 1
                        finally:
                            pbar.update(1)

            except KeyboardInterrupt:
                logger.warning("‚ö†Ô∏è  Execu√ß√£o interrompida pelo usu√°rio (KeyboardInterrupt). Salvando progresso parcial...")
                # stop_processing j√° ser√° True pelo handler; fora do la√ßo iremos exportar o parcial

        # Resumo final
        logger.info("\n" + "=" * 60)
        logger.info("üìä RESUMO DO PROCESSAMENTO")
        logger.info("=" * 60)
        logger.info(f"‚úì Arquivos processados com sucesso: {arquivos_processados}")
        if arquivos_erro > 0:
            logger.warning(f"‚ö†Ô∏è  Arquivos com erro: {arquivos_erro}")
        if arquivos_ignorados > 0:
            logger.info(f"‚è≠Ô∏è Arquivos ignorados (fora do filtro de ano): {arquivos_ignorados}")
        logger.info(f"üìà Total de registros extra√≠dos: {len(todos_dados)}")
        logger.info("=" * 60)

        df = pd.DataFrame(todos_dados)
        return df

    except Exception as e:
        logger.error(f"‚úó Erro inesperado durante o processamento: {str(e)}")
        logger.info("=" * 60)
        return pd.DataFrame()


def exportar_dados(df, formato=None):
    """Exporta os dados extra√≠dos para o formato especificado.
    
    Args:
        df (pd.DataFrame): DataFrame com os dados extra√≠dos
        formato (str): Formato de sa√≠da (csv, xlsx, json). Se None, usa config.
        
    Returns:
        bool: True se exportado com sucesso, False caso contr√°rio
    """
    if df.empty:
        logger.warning("‚ö†Ô∏è  Nenhum dado para exportar")
        return False
    
    try:
        # Obt√©m formato da config se n√£o fornecido
        if formato is None:
            formato = config.get_output_format().lower()
        
        # Cria pasta de output
        pasta_output = config.get_output_folder()
        if not os.path.exists(pasta_output):
            os.makedirs(pasta_output)
            logger.info(f"‚úì Pasta de sa√≠da criada: {pasta_output}")
        
        # Gera nome do arquivo com timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Exporta no formato escolhido
        if formato == 'csv':
            arquivo_saida = os.path.join(pasta_output, f"dados_extraidos_{timestamp}.csv")
            df.to_csv(arquivo_saida, index=False, encoding='utf-8-sig')
            logger.info(f"‚úì Dados exportados para CSV: {arquivo_saida}")
            logger.info(f"   Linhas: {len(df)} | Colunas: {len(df.columns)}")
            
        elif formato == 'xlsx':
            arquivo_saida = os.path.join(pasta_output, f"dados_extraidos_{timestamp}.xlsx")
            df.to_excel(arquivo_saida, index=False, sheet_name="Dados")
            logger.info(f"‚úì Dados exportados para XLSX: {arquivo_saida}")
            logger.info(f"   Linhas: {len(df)} | Colunas: {len(df.columns)}")
            
        elif formato == 'json':
            arquivo_saida = os.path.join(pasta_output, f"dados_extraidos_{timestamp}.json")
            df.to_json(arquivo_saida, orient='records', indent=2, force_ascii=False)
            logger.info(f"‚úì Dados exportados para JSON: {arquivo_saida}")
            logger.info(f"   Linhas: {len(df)} | Colunas: {len(df.columns)}")
        else:
            logger.error(f"‚úó Formato n√£o suportado: {formato}")
            logger.info("   Formatos suportados: csv, xlsx, json")
            return False
        
        return True
        
    except ImportError as e:
        if 'openpyxl' in str(e) and formato == 'xlsx':
            logger.error("‚úó Erro: openpyxl n√£o instalado. Para usar XLSX, instale com:")
            logger.error("   pip install openpyxl")
        else:
            logger.error(f"‚úó Biblioteca n√£o encontrada: {str(e)}")
        return False
    except Exception as e:
        logger.error(f"‚úó Erro ao exportar dados: {str(e)}")
        return False


if __name__ == "__main__":
    # Cria parser de argumentos de linha de comando
    parser = argparse.ArgumentParser(
        description="Extrator de Notas de Negocia√ß√£o da Clear Corretora",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  python3 extratorNotasCorretagem.py                    # Processa todos os PDFs
  python3 extratorNotasCorretagem.py --year 2024        # Processa apenas PDFs de 2024
  python3 extratorNotasCorretagem.py -y 2026            # Processa apenas PDFs de 2026
        """
    )
    parser.add_argument(
        '--year', '-y',
        type=int,
        default=None,
        help='Filtrar por ano (extrair apenas PDFs com esse ano no nome do arquivo)'
    )
    
    args = parser.parse_args()
    year_filter = args.year
    
    # Caminho da pasta com os arquivos de entrada
    caminho_pasta = config.get_input_folder()
    
    # Resolve o caminho absoluto
    caminho_absoluto = config.resolve_path(caminho_pasta)
    
    logger.info(f"üìÇ Diret√≥rio de entrada: {caminho_pasta}")
    logger.info(f"üîç Caminho absoluto: {caminho_absoluto}\n")
    
    # Se a pasta n√£o existe, tenta informar melhor
    if not os.path.exists(caminho_absoluto):
        logger.error(f"‚úó Pasta n√£o encontrada: {caminho_absoluto}")
        logger.info("\nüí° Dicas:")
        logger.info("   1. Verifique se o caminho est√° correto no arquivo application.properties")
        logger.info("   2. Certifique-se de que a pasta especificada existe")
        logger.info("   3. Coloque seus arquivos PDF ou ZIP dentro dessa pasta")
    else:
        logger.info("‚úì Pasta encontrada. Processando...\n")
        df = analisar_pasta_ou_zip(caminho_absoluto, year_filter=year_filter)
        
        if not df.empty:
            logger.info(f"\nüìã Primeiras linhas dos dados extra√≠dos:")
            logger.info(f"\n{df.head()}")
            
            # Exporta os dados
            logger.info("\n" + "=" * 60)
            logger.info("üíæ EXPORTANDO DADOS")
            logger.info("=" * 60)
            formato = config.get_output_format()
            sucesso = exportar_dados(df, formato)
            
            if sucesso:
                logger.info(f"\n‚úì Processamento conclu√≠do com sucesso!")
            else:
                logger.warning("‚ö†Ô∏è  Dados extra√≠dos mas n√£o foi poss√≠vel exportar.")
        else:
            logger.warning("‚ö†Ô∏è  Nenhum dado foi extra√≠do. Verifique os arquivos PDF na pasta.")
